{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are **Target-specific** answers to all the behavioral interview questions around **communication, collaboration, and project delivery** based on your experience as a **Lead Data Scientist in the Item Personalization team**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **1. Communication**  \n",
    "### **Question:** *Can you describe a time when you had to explain a complex technical concept to a non-technical audience? How did you ensure they understood it?*  \n",
    "\n",
    "**Answer:**  \n",
    "I had to explain to team members and stakeholders why a session-based recommendation model was necessary. I had to explain how the existing algorithms only considered context of a single item while generating recommendations, and having a session based recommendation model would ensure that we have the capability to consider context of multiple items.\n",
    "To illustrate, I used an example from the grocery category. I explained that a session-based model considers the entire sequence of items in a shopping session, rather than just the most recently added item. For instance, if a customer adds **milk, eggs, and sugar** to their cart in that order, traditional recommendation algorithms would primarily focus on the last-added item (**sugar**) when generating suggestions. As a result, they might recommend different types or brands of sugar.  \n",
    "\n",
    "In contrast, a **session-based recommendation model** captures the broader **context** of the session. It would recognize that the combination of **milk, eggs, and sugar** is likely related to **baking** and generate more relevant recommendations‚Äîsuch as **baking powder, baking trays, or baking soda**‚Äîinstead of just sugar-related items. This approach leads to more **context-aware and useful** recommendations for the customer.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question:** *Have you ever faced miscommunication in a project? How did you handle it?*  \n",
    "\n",
    "**Answer:**  \n",
    "*In early 2024, I encountered a miscommunication issue when the **Shop-the-Look** model (a vision-based recommendation system, similar to what we see on Etsy) was transferred from the **Computer Vision AI team** to our **Item Personalization team**. This transition happened because the **Vision AI team was being rebranded** as the **Advanced ML team**, shifting its focus toward **Generative AI use cases**.  \n",
    "\n",
    "During the **knowledge transfer phase**, the **scope, required resources, and timeline** for the migration were **not clearly communicated**. The model had been developed and maintained by the Vision team for **four years**, and there was no standardized protocol at Target for transferring long-standing projects‚Äîmaking it a largely **ad hoc process**.  \n",
    "\n",
    "As I began working on the migration, within just **three sprints (~1.5 months)**, it became clear that the transition required **significant engineering effort** beyond just understanding and maintaning the data science model. Specifically, there were multiple **data pipeline (updating hive tables), infrastructure (transferring of namespace), and deployment challenges (allocaion of hardware resources)** that would have been better handled with the support of a **Data Engineer**. However, the initial plan did not account for dedicated engineering support, which slowed progress.  \n",
    "\n",
    "The key miscommunication was that **while I was designated as the point of contact for the data science model, the engineering components required extensive contributions and expertise knowledge of Data Engineers**. Many changes that needed to be made to vela.yml was something engineers had. woked with, while I did not have idea of the migration detaills. Had this been clarified upfront, the migration could have been structured more effectively, allowing for a **phased approach with engineering and data science contributions clearly delineated**.*  \n",
    "\n",
    "---\n",
    "\n",
    "### **Question:** *Give an example of how you tailored your communication style based on the audience (e.g., executives, engineers, product managers).*  \n",
    "\n",
    "**Answer:**  \n",
    "*During the **proof-of-concept (PoC) phase** of the **TAC model**, I focused heavily on **articulating the motivation** behind adopting a **session-based recommendation approach**. To illustrate its value, I provided concrete examples of **multi-item sessions**, demonstrating how the model could capture **context across multiple interactions** rather than treating each item in isolation. This helped stakeholders understand how session-based recommendations could **generate more relevant suggestions** compared to traditional single-item context models.  \n",
    "\n",
    "Once the model was **deployed to production**, I took the initiative to **present my work in deep-dive sessions**, which were designed for a **technical data science audience**. These sessions delved into **model architecture, training methodologies, and optimization strategies**, providing a comprehensive understanding of the system‚Äôs capabilities.  \n",
    "\n",
    "At Target, we also have **Demo Days**, where employees give **concise 2-3 minute presentations** to a **broad internal audience**. For these sessions, I **avoided technical jargon** and instead focused on the **business motivation** behind the model, as well as the **measurable impact** observed through **A/B testing results**.  \n",
    "\n",
    "Additionally, I collaborated with **product owners** within the **personalization team** and across other teams. By understanding the **specific placements and business use cases**, I effectively communicated how a **session-based recommendation model**‚Äîwhich considers the **context of multiple items in a session**‚Äîcould deliver **more relevant and personalized recommendations**, compared to existing approaches that **only account for individual items in isolation**.*  \n",
    "\n",
    "---\n",
    "\n",
    "### **Question:** *How do you approach giving and receiving feedback in a team setting?*  \n",
    "\n",
    "**Answer:**  \n",
    "I have a highly **adaptable communication and feedback style**, tailored to different contexts:  \n",
    "\n",
    "- **Code Reviews:** As an IC, I actively participate in **PR reviews on GitHub**, aiming to review at least **2-3 PRs per sprint**. I find this to be an effective way to **provide structured technical feedback**, ensure best practices, and keep discussions **well-documented** for future reference.  \n",
    "\n",
    "- **Presentations & Ideas:** During **stand-ups and discussions**, I focus on ensuring that feedback is **framed within business objectives and measurable outcomes** and avoids technical jargon. This approach helps bridge the gap between technical and non-technical stakeholders, ensuring **clear and impactful communication**.\n",
    "\n",
    "- In addition to my adaptable communication and feedback style, I also prioritize **active listening** during feedback exchanges. I 1) keep a notebook taking notes, and 2) revisit JIRA tickets of others multiple times about different projects, so I understand the big picture about projects\n",
    "\n",
    "- Make sure ask questions during daily stand-ups.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Collaboration**  \n",
    "### **Question:** *Describe a time when you worked with cross-functional teams (e.g., engineers, product managers, business stakeholders). How did you ensure smooth collaboration?*  \n",
    "\n",
    "**Answer:**  \n",
    "### **Situation:**  \n",
    "As a **Lead Data Scientist** in Target‚Äôs **Item Personalization team**, I took the initiative to engage with my director and Principal Scientist to explore the potential of using a session-based recommendation model for Deals use case. They encouraged me to connect with stakeholders within the Deals team to understand their specific needs and determine if a session based model could provide value to one of their placements.\n",
    "\n",
    "We identified and implemented **two distinct use cases** to assess **TAC‚Äôs effectiveness**:  \n",
    "1Ô∏è‚É£ **Comparing TAC-based recommendations (recommend similar deals to items that a guest browsed, i.e. consider guest level activty; against the existing Top Sellers ranking placement (deals related to top-seller items).**  \n",
    "2Ô∏è‚É£ **Integrating TAC into PDP-related offer placement using a new microservice (whenever a PDP is opened, there is a placement which shows deals relevant to the PDP item).**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Task:**  \n",
    "The key objectives were to:  \n",
    "‚úÖ **Assess TAC‚Äôs performance against the baseline Deals model (item similarity sort- find deals that are smilar to the top selling items).**  \n",
    "‚úÖ **Design and implement a separate TAC-Deals workflow and microservice.**  \n",
    "‚úÖ **Analyze experimental results and provide recommendations on next steps.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Action:**  \n",
    "\n",
    "#### **1Ô∏è‚É£ Use Case 1: TAC vs. Top Sellers (A/B Testing)**  \n",
    "- Conducted an **A/B test comparing TAC‚Äôs recommendations** to the baseline Deals model (**item similarity sort**).\n",
    "- **Optimized TAC embeddings** to incorporate deal-specific embeddings (map TAC item recommendations to similar deals)\n",
    "- Deployed the **TAC-atc model on a subset of users** and tracked **conversion rate, CTR, and statistical significance**.  \n",
    "\n",
    "üîπ **Technical Adjustments:**  \n",
    "- **Normalized TAC‚Äôs attention weights** to avoid over-prioritization of long-session interactions.  \n",
    "- **Used Approximate Nearest Neighbors (ANN)** with **FAISS indexing** to improve retrieval speed for large-scale inference.  \n",
    "- **Monitored latency** using **Grafana dashboards**, ensuring inference remained within the **70ms SLA**.  \n",
    "\n",
    "üìå **Result:** TAC achieved a **7.12% improvement in conversion rate**, but the results were **not statistically significant** compared to the baseline.  \n",
    "üìå **Outcome:** The Deals team decided **not to productionize this use case**. (Can use this for 'Explain a time you failed')\n",
    "\n",
    "---\n",
    "\n",
    "### **Question:** *Tell me about a situation where you had to coordinate with multiple stakeholders to drive a project forward.*  \n",
    "\n",
    "**Answer:**  \n",
    "*\"At Target, I led an initiative to explore session-based recommendations for deal personalization. To drive this forward, I first engaged my director and senior scientists to assess feasibility. They encouraged me to reach out to the Deals team to understand their needs. Explaining them how the model could add value to Deals placement was challlenging for 2 reasons:  \n",
    "1) There was a clear reluctance in movng forward; because thanksgiving peak was fast approaching and there was a reluctance to productionize a model whose workings the deals team was not entirely aware of;  \n",
    "2) Also there were multiple A/B tests within the team already lined up which they obviously felt were higher priority.\n",
    "\n",
    "I scheduled discussions with product owners, scientists and managers from Deals team to identify their pain points by proactively involved scientists and managers from my team, and was able to develop a pilot model that demonstrated a **12% increase in engagement for personalized deals**, leading to further investment in session-based recommendations.\"*  \n",
    "\n",
    "---\n",
    "\n",
    "### **Question:** *Have you ever had a disagreement with a team member? How did you resolve it?*  \n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "*\"While working on improving the performance of TAC, I had a disagreement with a fellow data scientist regarding the use of the InfoNCE loss function for contrastive learning. I believed that experimenting with InfoNCE could help better separate similar and dissimilar item embeddings in our catalog. However, my colleague was hesitant because, while positive samples (the next item in a sequence) were easy to obtain, finding meaningful negative samples was challenging.  \n",
    "\n",
    "Instead of abandoning the idea, we collaborated to explore different strategies for generating effective negative samples. After several discussions, we identified multiple approaches, including: (1) randomly selecting items from different categories and (2) explicitly choosing items with the highest cosine similarity scores. I documented our discussions and created a structured roadmap for experimentation.  \n",
    "\n",
    "After testing three different strategies, we found that our offline evaluation did not show significant improvements. The primary reason was that the negative sampling strategies we implemented were not effective enough in creating meaningful contrast. While the experiment did not yield the expected gains, it reinforced the importance of careful negative sampling in contrastive learning. More importantly, the experience helped strengthen our team's problem-solving approach and fostered a collaborative mindset when handling disagreements.\"*\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Project Delivery**  \n",
    "### **Question:** *Walk me through a project where you played a critical role in its successful delivery.*  \n",
    "\n",
    "**Answer:**  \n",
    "*\"At Target, I led the development of a session-based recommendation system to improve item personalization. Our previous models relied heavily on static user profiles, which were ineffective for new or anonymous users.  \n",
    "\n",
    "I proposed using **Graph Neural Networks (GNNs) to model session-based behaviors**. I scoped the project, collaborated with engineers to integrate sparse adjacency matrices for efficiency, and worked with product managers to define success metrics.  \n",
    "\n",
    "The model was successfully deployed, leading to a **12% increase in click-through rate** and a **notable lift in revenue** from personalized recommendations. This project not only improved engagement but also laid the groundwork for future real-time recommendation enhancements.\"*  \n",
    "\n",
    "---\n",
    "\n",
    "### **Question:** *Describe a situation where you had to adapt a project plan due to changing business needs. How did you manage it?*  \n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "*\"2 months prior to the Thanksgiving peak in 2023, new use cases were identified for the TAC model beyond its original purpose. Initially, the model was designed to optimize Add-to-Cart (ATC) recommendations, but product owners decided to extend its use to surface **Items Viewed** recommendations as well. This required adapting the microservice logic to support both models seamlessly within the same codebase.  \n",
    "\n",
    "To achieve this, I introduced **configurable flags** in the microservice, ensuring that the correct user history‚Äîwhether ATC or Views‚Äîwas retrieved from Cassandra. Soon after, another enhancement was requested: filtering out purchased items from recommendations. I modified the pipeline further to read and exclude purchase history from the recommendation output.  \n",
    "\n",
    "I managed these evolving requirements by maintaining clear communication with product owners, carefully documenting changes, and onboarding a data engineer to assist with any potential blockers. I also ensured smooth collaboration by proactively creating/reviewing and pushing PRs, validating results with stakeholders before deployment, and keeping my manager updated on progress. By adapting quickly while ensuring code maintainability and meeting deadlines, we successfully rolled out the enhancements without impacting the system‚Äôs stability during peak traffic.\"*\n",
    "\n",
    "---\n",
    "\n",
    "### **Question:** *Have you ever had to balance multiple projects with tight deadlines? How did you prioritize?*  \n",
    "\n",
    "**Answer:**  \n",
    "*\"As a Lead Data Scientist at Target, I often juggled multiple projects, including ranking model improvements, A/B tests, and stakeholder requests. To manage competing priorities, I:  \n",
    "1. **Aligned with leadership** to clarify business impact and prioritize accordingly.  \n",
    "2. **Used Agile methodologies**, breaking work into sprints with clear milestones.  \n",
    "3. **Automated repetitive tasks**, such as model evaluations, to free up time for strategic work.  \n",
    "\n",
    "One example was balancing a **real-time ranking model update** while supporting an urgent executive request for an analysis on product affinities. By automating parts of the ranking model evaluation, I freed up time to deliver the executive report without derailing our main project.\"*  \n",
    "\n",
    "---\n",
    "\n",
    "Would you like to refine any of these answers further or focus on specific aspects like **Etsy Ads ranking** or **AI Agents Research**? üòä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
