{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Situation:**  \n",
    "As the **item catalog size increased** and the number of concurrent requests grew (especially during ), we started experiencing **latency issues**, struggling to meet our **SLA of 70 milliseconds** for inference. Given the complexity of **graph computations and attention mechanisms**, inference time was a bottleneck, impacting real-time recommendations.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Task:**  \n",
    "My goal was to **optimize the training and inference pipeline** to ensure that the model could handle the growing catalog size while keeping the response time within the SLA.  \n",
    "\n",
    "I had to:  \n",
    "‚úÖ Identify bottlenecks in the **model architecture, data pipelines, and compute efficiency**.  \n",
    "‚úÖ Improve inference speed without significantly compromising model accuracy.  \n",
    "‚úÖ Ensure the **deployment pipeline scaled efficiently** with increasing data volume. Specifically, when scaling the model to multiple nodes (horizontal scaling), performance did not scale linearly, leading to high request latencies and uneven load distribution. \n",
    "\n",
    "---\n",
    "\n",
    "### **Action:**   \n",
    "\n",
    "#### **1Ô∏è‚É£ Optimizing Model Architecture & Computation Efficiency** \n",
    "- **Quantized the Model**: Used **TorchScript with FP16 precision** to reduce model size and speed up inference.  \n",
    "- **Optimized Attention Mechanism**: Replaced the standard **scaled dot-product attention** with an **approximate attention mechanism** (e.g., **performing key-query projection with lower-dimensional embeddings**). \n",
    "- Optimized dgl aggregation() to use a pre-defined method (mean()) during model inferencing instead of user-defined GRU aggregation.\n",
    "\n",
    "#### **2Ô∏è‚É£ Enhancing Data Pipeline**  \n",
    "- **Sparse Tensor Optimization**: Instead of storing large adjacency matrices, I utilized **sparse representations with PyTorch SparseTensors**, reducing computation overhead.  \n",
    "- At inference layer, ensures caching of guest session history was enabled.\n",
    "\n",
    "---\n",
    "\n",
    "## TODOs\n",
    "\n",
    "#### **3Ô∏è‚É£ Improving Deployment & Hardware Utilization**  \n",
    "- **ONNX Runtime Acceleration**: Converted the PyTorch model to **ONNX** and used **ONNX Runtime** for optimized inference.  \n",
    "- **Parallelized Batch Processing**: Deployed the model with **TorchServe** and enabled **asynchronous batch inference**, reducing per-request compute time.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Result:**  \n",
    "üìå **Inference latency reduced by ~40%**, bringing down the 95% response time from **95ms ‚Üí ~55ms**, meeting the SLA of 70ms.  \n",
    "üìå **Model maintained >98% of original accuracy**, despite optimizations.     \n",
    "\n",
    "---\n",
    "\n",
    "Would you like to tailor this further to focus on **collaborating with engineers, trade-offs, or a different challenge**? üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here‚Äôs an enhanced **STAR response** with more **technical depth** on how **TAC was applied to deal recommendations**:  \n",
    "\n",
    "---\n",
    "\n",
    "### **Situation:**  \n",
    "At Target, I was leading **ML initiatives in the Item PRZ team**, focusing on **session-based recommendation models**. Our primary focus was on **personalizing product recommendations**, but I saw an opportunity to extend our TAC to **deal recommendations** in the **Deals PRZ team**.  \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Situation:**  \n",
    "As a **Lead Data Scientist** in Target‚Äôs **Item Personalization team**, I took the initiative to engage with my director and Principal Scientist to explore the potential of using a session-based recommendation model for Deals use case. They encouraged me to connect with stakeholders within the Deals team to understand their specific needs and determine if a session based model could provide value to one of their placements.\n",
    "\n",
    "We identified and implemented **two distinct use cases** to assess **TAC‚Äôs effectiveness**:  \n",
    "1Ô∏è‚É£ **Comparing TAC-based recommendations (recommend similar deals to items that a guest browsed, i.e. consider guest level activty; against the existing Top Sellers ranking placement (overall top-seller items ).**  \n",
    "2Ô∏è‚É£ **Integrating TAC into PDP-related offer placement using a new microservice.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Task:**  \n",
    "The key objectives were to:  \n",
    "‚úÖ **Assess TAC‚Äôs performance against the baseline Deals model (item similarity sort- find deals that are smilar to the top selling items).**  \n",
    "‚úÖ **Design and implement a separate TAC-Deals workflow and microservice.**  \n",
    "‚úÖ **Analyze experimental results and provide recommendations on next steps.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Action:**  \n",
    "\n",
    "#### **1Ô∏è‚É£ Use Case 1: TAC vs. Top Sellers (A/B Testing)**  \n",
    "- Conducted an **A/B test comparing TAC‚Äôs recommendations** to the baseline Deals model (**item similarity sort**).  \n",
    "- **Optimized TAC embeddings** to incorporate deal-specific embeddings (map TAC item recommendations to similar deals)\n",
    "- Deployed the **TAC-atc model on a subset of users** and tracked **conversion rate, engagement rate, and statistical significance**.  \n",
    "\n",
    "üîπ **Technical Adjustments:**  \n",
    "- **Normalized TAC‚Äôs attention weights** to avoid over-prioritization of long-session interactions.  \n",
    "- **Used Approximate Nearest Neighbors (ANN)** with **FAISS indexing** to improve retrieval speed for large-scale inference.  \n",
    "- **Monitored latency** using **Grafana dashboards**, ensuring inference remained within the **70ms SLA**.  \n",
    "\n",
    "üìå **Result:** TAC achieved a **7.12% improvement in conversion rate**, but the results were **not statistically significant** compared to the baseline.  \n",
    "üìå **Outcome:** The Deals team decided **not to productionize this use case**. (Can use this for 'Explain a time you failed')\n",
    "\n",
    "---\n",
    "\n",
    "#### **2Ô∏è‚É£ Use Case 2: TAC-Deals Integration for PDP Offer Placement**  \n",
    "- Designed and implemented a **new training workflow and microservice (TAC-Deals)** to test **session-based deal recommendations** on **Product Detail Pages (PDPs)**.  \n",
    "- Experimented with **three variations**:  \n",
    "  - **Control**: Existing item-related offers.  \n",
    "  - **V1**: TAC-Deals model.  \n",
    "  - **V2**: Hybrid approach (item-related offers + offer similarity sort).  \n",
    "- Integrated the TAC-Deals model into **Target‚Äôs real-time inference pipeline**, ensuring it could handle **high-traffic PDP requests** with **low-latency inference**.  \n",
    "\n",
    "üîπ **Engineering Enhancements:**    \n",
    "- **Implemented model quantization** via **ONNX Runtime** to reduce inference latency.  \n",
    "- **Parallelized model inference** across GPUs using **TorchServe with Kubernetes auto-scaling**.  \n",
    "- **Logged real-time user interactions** via **Kafka streaming**, feeding insights back into model retraining.  \n",
    "\n",
    "üìå **Result:** The **Control group outperformed** both TAC-based variations (**V1 & V2**) in terms of **interaction rate and display-to-conversion rate**.  \n",
    "üìå **Outcome:** Highlighted **opportunities for further refinement**, including:  \n",
    "   - **Re-weighting short-term user intent in TAC‚Äôs attention mechanism.**  \n",
    "   - **Exploring multi-task learning to better balance deal conversions and engagement.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Result & Learnings:**  \n",
    "‚úÖ **Demonstrated TAC‚Äôs adaptability** for cross-team use cases, even though **initial results were inconclusive**.  \n",
    "‚úÖ **Provided actionable insights** for refining TAC in future deal applications.  \n",
    "‚úÖ **Established a scalable TAC-Deals microservice**, allowing future optimizations.  \n",
    "‚úÖ **Validated experimental rigor** with well-structured A/B testing and real-world deployment.  \n",
    "\n",
    "---\n",
    "\n",
    "Would you like further refinements, such as **highlighting leadership aspects or next steps for improving TAC in Deals?** üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
