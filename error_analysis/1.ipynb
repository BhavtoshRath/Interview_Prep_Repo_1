{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some **easy to medium-level debugging and error analysis questions** for TensorFlow, along with code examples and explanations.  \n",
    "\n",
    "---\n",
    "\n",
    "### **1. Debugging Shape Mismatch in Model Input**  \n",
    "**Question:**  \n",
    "The following code tries to train a simple neural network but runs into a shape mismatch error. Fix it.  \n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Dummy data\n",
    "X_train = tf.random.normal((100,))  # 1D tensor instead of 2D\n",
    "y_train = tf.random.uniform((100,), maxval=2, dtype=tf.int32)\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(10,)),  # Input shape issue\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "```\n",
    "\n",
    "**Solution:**  \n",
    "The issue is that `X_train` is **1D**, but the model expects a **2D input with shape (None, 10)**. We need to reshape `X_train` to `(100, 10)`.  \n",
    "\n",
    "```python\n",
    "X_train = tf.random.normal((100, 10))  # Now it's 2D\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Handling NaNs in Training Data**  \n",
    "**Question:**  \n",
    "You notice that your loss becomes `NaN` during training. How do you debug the issue?  \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a dataset with NaNs\n",
    "X_train = np.random.randn(100, 5)\n",
    "y_train = np.random.randint(0, 2, size=(100,))\n",
    "\n",
    "# Inject NaN values\n",
    "X_train[0, 0] = np.nan\n",
    "\n",
    "# Build simple model\n",
    "model = tf.keras.Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(5,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "```\n",
    "\n",
    "**Solution:**  \n",
    "To debug NaNs in the dataset, use `np.isnan()` to check for missing values.  \n",
    "\n",
    "```python\n",
    "print(np.isnan(X_train).any())  # True, indicates NaNs are present\n",
    "```\n",
    "\n",
    "Fix it by replacing NaNs:  \n",
    "\n",
    "```python\n",
    "X_train = np.nan_to_num(X_train)  # Replace NaNs with 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Fixing Incorrect Loss Function for Multi-Class Classification**  \n",
    "**Question:**  \n",
    "The following code trains a model for multi-class classification but throws an error. Fix it.  \n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Dummy data\n",
    "X_train = tf.random.normal((100, 10))\n",
    "y_train = tf.random.uniform((100,), maxval=3, dtype=tf.int32)  # 3 classes\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(10,)),\n",
    "    Dense(3, activation='softmax')  # 3 output classes\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])  # Wrong loss function\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "```\n",
    "\n",
    "**Solution:**  \n",
    "Since this is a multi-class classification problem, we should use `SparseCategoricalCrossentropy` instead of `mean_squared_error`.  \n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### **Comparison Table** (BR)\n",
    "| Criterion | Binary Cross-Entropy | Sparse Categorical Cross-Entropy |\n",
    "|-----------|----------------------|---------------------------------|\n",
    "| **Number of Classes** | 2 (binary) or multi-label | More than 2 (multi-class) |\n",
    "| **Label Format** | Single 0/1 value per sample | Integer class labels (e.g., `0,1,2,...`) |\n",
    "| **Model Output** | `sigmoid` activation, single neuron | `softmax` activation, neurons = number of classes |\n",
    "| **Example Task** | Spam detection, disease prediction | Image classification, sentiment analysis with >2 classes |\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Mistakes**\n",
    "âŒ Using `binary_crossentropy` for multi-class classification  \n",
    "âŒ Using `sparse_categorical_crossentropy` with one-hot encoded labels (instead, use `categorical_crossentropy`)  \n",
    "âŒ Forgetting to match the activation function with the correct loss function (`sigmoid` for BCE, `softmax` for SCE)\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Handling Exploding Gradients in Deep Networks**  \n",
    "**Question:**  \n",
    "Your deep neural network performs poorly because of **exploding gradients**. How do you fix it?  \n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Model with deep architecture\n",
    "model = tf.keras.Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(20,)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "**Solution:**  \n",
    "- Use **gradient clipping** to prevent extreme updates.  \n",
    "\n",
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam(clipnorm=1.0)  # Clips gradients\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "- Try **Batch Normalization** or **smaller learning rate**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **5. Fixing Incorrect Accuracy Calculation in Multi-Label Classification**  \n",
    "**Question:**  \n",
    "You are working on a **multi-label classification** task where each sample can belong to multiple classes. The following code uses `accuracy` as a metric, but it produces misleading results. Fix it.  \n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Dummy data\n",
    "X_train = tf.random.normal((100, 10))\n",
    "y_train = tf.random.uniform((100, 3), maxval=2, dtype=tf.int32)  # Multi-label (each sample has multiple 0/1 labels)\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(10,)),\n",
    "    Dense(3, activation='sigmoid')  # Multi-label output\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "```\n",
    "\n",
    "**Solution:**  \n",
    "- Use **binary cross-entropy** instead of sparse categorical cross-entropy, since each class is **independent**.  \n",
    "- Use **`AUC`** or **`F1-score`** instead of `accuracy` for multi-label problems.  \n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Bonus: Detecting Silent Errors in Model Training**  \n",
    "If you want to **detect silent numerical issues** during training, use:  \n",
    "\n",
    "```python\n",
    "tf.debugging.enable_check_numerics()  # Detects NaNs or Infs in TensorFlow tensors\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Debugging Issues and Fixes**\n",
    "| Issue | Fix |\n",
    "|---------------------------|----------------------------------------|\n",
    "| Shape mismatch error | Ensure correct input shape for training data |\n",
    "| NaNs in dataset | Check with `np.isnan()` and replace using `np.nan_to_num()` |\n",
    "| Wrong loss function for classification | Use `sparse_categorical_crossentropy` for integer labels, `categorical_crossentropy` for one-hot labels |\n",
    "| Exploding gradients | Use **gradient clipping**, **batch normalization**, or reduce learning rate |\n",
    "| Wrong metric for multi-label classification | Use `binary_crossentropy` and **AUC** instead of `accuracy` |\n",
    "\n",
    "Would you like more debugging examples? ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some **easy to medium debugging and error analysis questions** related to TensorFlow code. These examples will help you practice identifying and fixing common issues in machine learning pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 1: Debugging a Shape Mismatch**\n",
    "You are training a model, but you encounter the following error:\n",
    "```\n",
    "ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
    "```\n",
    "\n",
    "#### **Code**:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # Output layer with 10 units\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "X_train = tf.random.normal((1000, 32))\n",
    "y_train = tf.random.uniform((1000,), maxval=10, dtype=tf.int32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "```\n",
    "\n",
    "#### **Issue**:\n",
    "The error occurs because `sparse_categorical_crossentropy` expects `y_train` to be integer labels (shape `(None,)`), but the output layer produces a probability distribution over 10 classes (shape `(None, 10)`). The shapes are incompatible.\n",
    "\n",
    "#### **Fix**:\n",
    "Ensure the output layer matches the loss function. Since `y_train` is integer labels, the output layer should have 10 units with a `softmax` activation, and the loss should remain `sparse_categorical_crossentropy`.\n",
    "\n",
    "```python\n",
    "# No changes needed; the code is correct.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 2: Debugging a NaN Loss**\n",
    "You are training a model, but the loss becomes `NaN` after a few epochs. Debug the issue.\n",
    "\n",
    "#### **Code**:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "X_train = tf.random.normal((1000, 32))\n",
    "y_train = tf.random.uniform((1000,), maxval=2, dtype=tf.int32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "```\n",
    "\n",
    "#### **Issue**:\n",
    "The issue is likely due to the data. If `y_train` contains values other than `0` or `1`, the `binary_crossentropy` loss can produce `NaN` values.\n",
    "\n",
    "#### **Fix**:\n",
    "Ensure `y_train` contains only `0` or `1` for binary classification.\n",
    "\n",
    "```python\n",
    "# Convert y_train to binary labels (0 or 1)\n",
    "y_train = tf.cast(y_train, dtype=tf.float32)\n",
    "y_train = tf.where(y_train > 0, 1.0, 0.0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 3: Debugging a Slow Training Process**\n",
    "You notice that the training process is very slow. Identify potential issues and suggest improvements.\n",
    "\n",
    "#### **Code**:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(1000,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "X_train = tf.random.normal((10000, 1000))\n",
    "y_train = tf.random.uniform((10000,), maxval=2, dtype=tf.int32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "```\n",
    "\n",
    "#### **Issue**:\n",
    "The input data has a very high dimensionality (`1000` features), which can make training slow. Additionally, the model architecture might be too simple for the data.\n",
    "\n",
    "#### **Fix**:\n",
    "1. **Reduce Dimensionality**: Use dimensionality reduction techniques like PCA or feature selection.\n",
    "2. **Increase Model Capacity**: Add more layers or units to the model.\n",
    "3. **Use Batch Training**: Ensure the data is batched properly.\n",
    "\n",
    "```python\n",
    "# Example: Increase model capacity\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(1000,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 4: Debugging Overfitting**\n",
    "You notice that the model performs well on the training data but poorly on the validation data. Debug the issue.\n",
    "\n",
    "#### **Code**:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(32,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "X_train = tf.random.normal((1000, 32))\n",
    "y_train = tf.random.uniform((1000,), maxval=2, dtype=tf.int32)\n",
    "X_val = tf.random.normal((200, 32))\n",
    "y_val = tf.random.uniform((200,), maxval=2, dtype=tf.int32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "```\n",
    "\n",
    "#### **Issue**:\n",
    "The model is overfitting because it is too complex relative to the amount of training data.\n",
    "\n",
    "#### **Fix**:\n",
    "1. **Add Regularization**: Use dropout or L2 regularization.\n",
    "2. **Reduce Model Complexity**: Use fewer layers or units.\n",
    "3. **Early Stopping**: Stop training when validation performance stops improving.\n",
    "\n",
    "```python\n",
    "# Add dropout and early stopping\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(32,)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Add early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 5: Debugging a Data Pipeline Issue**\n",
    "You are using a `tf.data.Dataset` pipeline, but the model is not training. Debug the issue.\n",
    "\n",
    "#### **Code**:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=10)\n",
    "```\n",
    "\n",
    "#### **Issue**:\n",
    "The dataset is not being shuffled, which can lead to poor training performance.\n",
    "\n",
    "#### **Fix**:\n",
    "Shuffle the dataset before batching.\n",
    "\n",
    "```python\n",
    "# Shuffle the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=10)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "These examples cover common debugging scenarios in TensorFlow, including:\n",
    "1. Shape mismatches.\n",
    "2. NaN losses.\n",
    "3. Slow training.\n",
    "4. Overfitting.\n",
    "5. Data pipeline issues.\n",
    "\n",
    "Practicing these will help you develop strong debugging and error analysis skills for TensorFlow code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
